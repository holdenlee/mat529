
\blu{3/30/16}

Here is an equivalent formulation of the Kirszbraun extension theorem.
\begin{thm}
Let $H_1,H_2$ be Hilbert spaces, $\{x_i\}_{i\in I}\subeq H_1$, $\{y_i\}_{i\in I}\subeq H_2$, $\{r_i\}_{i=1}^{\iy}\subeq (0,\iy)$. Suppose that $\ve{y_i-y_j}_{H_2}\le \ve{x_i-x_j}_{H_2}$ for all $i,j\in I$. Then $\bigcap_{i\in I} B_{H_1}(x_i,r_i) \ne \phi$ implies $\bigcap_{i\in I} B_{H_2} (y_i,r_i) \ne \phi$. 
\end{thm}
\begin{proof}
By weak compactness and orthogonal projection, it is enough to prove this when $I=\{1,\ldots, n\}$ and $H_1,H_2$ are both finite dimensional. Fix any $x\in \bigcap_{i=1}^n B_{H_1}(x_i,r_i)$. If $x=x_{i_0}$ for some $i_0\in \{1,\ldots, n\}$, $\ve{y_{i_0}-y_i}_{H_2}\le \ve{x_{i_0}-x_i}_{H_1}\le r_i$, and $y_{i_0}\in \bigcap_{i=1}^n B_{H_2}(y_i,r_i)$. Assume $x\nin \{x_1,\ldots, x_n\}$. 

Define $f:H\to \R$ by 
\[
f(y) = \max \bc{
\fc{\ve{y-y_1}_{H_2}}{\ve{x-x_1}_{H_1}}, \ldots, \fc{\ve{y-y_n}_{H_2}}{\ve{x-x_n}_{H_2}}
}.
\]
Note that $f$ is continuous and $\lim_{\ve{y}_{H_2}\to \iy} f(y)=\iy$.

So, the minimum of $f(y)$ over $\R^n$ is attained. Let 
\[
m=\min_{y\in \R^n} f(y).
\]
Fix $y\in \R^n$, $f(y)=m$.

Observe that we are done if $m\le 1$.
Suppose \bwoc{} $m>1$. Let $J$ be the indices where the ratio is the minimum. 
\[
J=\set{i\in \{1,\ldots, n\}}{\fc{\ve{y-y_i}_{H_2}}{\ve{x-x_i}_{H_1}}=m}.
\]
By definition, if $j\in J$, then $\ve{y-y_j}_{H_2}=m\ve{x-x_j}_{H_1}$, and for $j\nin J$, $\ve{y-y_j}_{H_2}<m\ve{x-x_j}_{H_1}$. 

\begin{clm}
$y\in \conv(\{y_j\}_{j\in J})$.
\end{clm}
\begin{proof}
If not, find a separating hyperplane. If we move $y$ a small enough distance towards $\conv(\{y_j\}_{j\in J})$ perpendicular to the separating hyperplane to $y'$, then for $j\in J$,
\[
\ve{y'-y_j}_{H_2}<\ve{y-y_j}_{H_2} = m\ve{x-x_j}_{H_1}.
\]
For $j\in J$, it is still true that $\ve{y'-y_j}_{H_2}<m\ve{x-x_j}_{H_1}$. Then $f(y')<m$, contradicting that $y$ is a minimizer.
\end{proof}

By the claim, there exists $\{\la_j\}_{j\in J}$, $\la_j\ge 0$, $\sum_{j\in J}\la_j=1$, $y=\sum_{j\in J}\la_jy_j$. 

We use this the coefficients of this convex combination to define a probability distribution. Define a random vector in $H_1$ by $X$, with
\[
\Pj(X=x_j) = \la_j,\quad j\in J.
\]
For all $j\in \{1,\ldots, n\}$, let $y_j=h(x_j)$. Let $\E[h(X)] = \sum_{j\in J} \la_jy_j=y$. Let $X'$ be an independent copy of $X$.

Using $\ve{h(X)-y}_{H_2} = m\ve{X-x}_{H_1}$, we have
\begin{align}%bwoc m>1
\E\ve{h(X)-\E h(X)}_{H_2}^2 & =\E \ve{h(X) - y}_{H_2}^2\\
&=m^2 \E\ve{X-x}_{H_1}^2\\
&> \E\ve{X-x}_{H_1}^2\\
&\ge \E\ve{X-EX}_{H_1}^2 \label{eq:kir1}
%&= \rc2 \E\ve{X-X'}_{H_2}^2.
\end{align}
%To see~\eqref{eq:kir1}, note
%\[
%E\ve{X-x}_{H_1}^2 \ge \E\ve{X-EX}_{H_1}^2
%\]
%expand
In Hilbert space, it is always true that 
\[
\E\ve{X-EX}_{H_1}^2 = \rc2 \E\ve{X-X'}_{H_2}^2.
\]
Using this on both sides of the above,
\[
\rc 2 \E\ve{h(X)-h(X')}_{H_2}^2 > \rc2\ve{X-X'}_{H_1}^2. 
\]

So far we haven't used the only assumption on the points. By the assumption $\ve{X-X'}_{H_1} \ge \ve{h(X)-h(X')}_{H_2}$. This is a contradiction.
\end{proof}
This is not true in $L^p$ spaces when $p\ne 2$, but there are other theorems one can formulate (ex. with different radii). We have to ask what happens to each of the inequalities in the proof.
As stated the theorem is a very ``Hilbertian" phenomenon.

\begin{df}
Let $(X,\ved_X)$ be a Banach space and $p\ge 1$. We say that $X$ has \ivocab{Rademacher type} $p$ if for every $n$, for every $x_1,\ldots, x_n\in X$, 
\[\pa{\EE_{\ep=(\ep_1,\ldots, \ep_n)\in \{\pm 1\}^n}\ba{\ve{\sumo in\ep_iX_i}^p_X}}^{\rc p}\le T\pa{\sumo in \ve{X_i}_X^p}^{\rc p}.
\] 
The smallest $T$ is denoted $T_p(X)$.
%2 is parallelogram identity. FOr other $p$ this is a generalization.
\end{df}
\begin{df*}[Definition~\ref{df:enflo}]
A metric space $(X,d_X)$ is said to have \ivocab{Enflo type} $p$ if for all $f:\{\pm 1\}^n\to X$,
\[
\pa{
\EE_{\ep} [d_X(f(\ep),f(-\ep))^p]
}^{\rc p}\lesssim_X
\pa{
\sumo jn \EE_{\ep} [d(f(\ep), f(\ep_1,\ldots,\ep_{j-1}, -\ep_j, \ep_{j+1},\cdots))^p]
}^{\rc p}.
\]
\end{df*}
If $X$ is also a Banach space of Enflo type $p$, then it is also of Rademacher type $p$. %linear functions.

\begin{qu}
Let $X$ be a Banach space of Rademacher type $p$. Does $X$ also have Enflo type $p$?
\end{qu}
We know special Banach spaces for which this is true, like $L^p$ spaces, but we don't know the anser in full generality.
\begin{thm}[Pisier]\llabel{thm:pisier}
Let $X$ be a Banach space of Rademacher type $p$. % Then $X$ has type $p-\ep$ for every $1>\ep>0$.
Then $X$ has Enflo type $q$ for every $1<q<p$.
\end{thm}
%set up to be trivially true when $p=1$ (by triangle ineq) All these things are 

We first need the following.
\begin{thm}[Kahane's Inequality]
For every $\iy>p,q\ge 1$, there exists $K_{p,q}$ such that for every Banach space, $(X,\ved_X)$ for every $x_1,\ldots, x_n\in X$, 
\[
\pa{\E\ve{\sumo in \ep_i x_i}_X^p}^{\rc p}\le K_{p,q}\pa{\E \ve{\sumo in \ep_i x_i}_X^q}^{\rc q}.
\]
%real: khintchine
\end{thm}
In the real case this is Khintchine's inequality.

By Kahane's inequality, $X$ has type $p$ iff
\[
\pa{\E\ve{\sumo in \ep_i x_i}_X^q}^{\rc q} \lesssim_{X,p,q} \pa{\sumo in \ve{x_i}_X^p}^{\rc p}.
\]

Define $T:\ell_p^n(X)\to L_p(\{\pm 1\}^n,X)$ by $T(x_1,\ldots, x_n)(\ep) = \sumo in \ep_iX_i$.
%vector valued 
%i will not discuss measurability

(Here $\ve{f}_{L_p(\{\pm 1\}^n,X)} = \pa{\rc{2^n} \sum_{\ep\in \{\pm 1\}^n} \ve{f(\ep)}_X^p}^{\rc p}$.)

%

Rademacher type $p$ mens
\[
\ve{T}_{\ell_p^n(X)\to L_q(\{\pm 1\}^n, X)}\lesssim_{X,p,q} 1.
\]
For an operator $T:Y\to Z$, the adjoint $T^*:Z^*\to Y^*$ satisfies 
\[
\ve{T}_{Y\to Z} = \ve{T^*}_{Z^*\to Y^*}. 
\]
%This is the usual duality we're used to.
Let $p^*=\fc{p}{p-1}$ be the dual of $p$ ($\rc{p}+\rc{p^*}=1$). Now 
\[
L_q(\{\pm 1\}^n, X)^*=L_{q^*} (\{\pm 1\}^n, X^*).
%finite dimensional
\]
Here, $g^*:\{\pm 1\}^n\to X^*$, $f:\{\pm 1\}^n\to X$, $g^*(f) = \E g^*(\ep) (f(\ep))$, $\ell_p^n(X) = \ell_{p^*}^n(X^*)$. 

Note 
\[\ve{T^*}_{L_{q^*}(\{\pm 1\}^n, X^*)\to \ell_{p^*}^n(X^*)}\lesssim 1,
\]
%formala for $T^*$. 
For $T:Y\to Z$, $T^*:Z^*\to Y^*$ is defined by $T^*(z^*)(y) = z^*(Ty)$. 

%natural $n$-tuple. Look at the Fourier transform. 
%field over 2 elements. 
For $g^*:\{\pm 1\}^n \to X^*$, $g^*  \sum_{A\subeq \{1,\ldots, n\}}\wh g^*(A)W_A$. %where $W_A(\ep)=\prod_{i\in A} \ep_i$.
%duality 5 times in every proof.
We claim
\[
T^*g^* = (\wh g^*(\{1\}),\ldots, \wh g(\{n\})). 
\]
We check
\bal
T^*g^* (x_1,\ldots, x_n)& = g^* (T(x_1,\ldots, x_n))\\
&\le
\E g^*(\ep) \pa{\sumo in \ep_iX_i}\\
&=\sumo in (\E g^*(\ep)\ep_i) (X_i)\\
&=\sumo in \pa{\sum_{A\subeq \{1,\ldots, n\}} \wh g^*(A) (\E W_A(\ep) \ep_i)}(x_i)\\
&=\sumo in \wh g^*(\{i\}) (x)\\
&= (\wh g^*(\{1\}),\ldots, \wh g^*(\{n\}))(x_1,\ldots, x_n).
\end{align*}
Rademacher type $p$ means for all $g_i^*:\{\pm 1\}^n \to X^*$, for all $q\in [1,\iy)$,
\[
\pa{\sumo in \ve{\wh g^*(\{i\})}_X^{p^*}} \lesssim \ve{g^*}_{L_q(\{\pm 1\}^n, X^*)}
\]
%Different way of writing Rademacher type.

\begin{thm}[Pisier]
If $X$ has Rademacher type $p$ and $1\le a<p$, then for every $b>1$, for all $f:\{\pm 1\}^n\to X$ with $\E f = 0$, 
\[
\ve{f}_b\precsim \ve{\pa{\sumo jn \ve{\pl_j f}_X^a}^{\rc a}}_b.
\]
\end{thm}
Here, for $f:\{\pm 1\}^n\to X$, $\pl_jf :\{\pm 1\}^n\to X$ is defined by 
\[
\pl_jf(\ep)  =\fc{f(\ep)- f(\ep_1,\ldots, \ep_{j-1},-\ep_j, \ep_{j+1},\ldots \ep_n)}2 = \sumr{A\subeq \{1,\ldots, n\}}{j\in A} \wh f(A) W_A.
\]
Note $\pl_j^2=\pl_j$. 

The Laplacian is $\De=\sumo jn \pl_j = \sumo jn \pl_j^2$. We've proved that
\[
\De f = \sum_{A\subeq \{1,\ldots,n\}} |A|\wh f(A) W_A.
\]
The heat semigroup on the cube\footnote{also known as the noise operator} is for $t>0$,
\[
e^{-t\De} f = \sum_{A\subeq \{1,\ldots, n\}} e^{-t|A|} \wh f(A)W_A.
\]
%heat flow proof of this, nice.
This is a function on the cube
\[
\ep \mapsto \pa{\sumo jn \ve{\pl_j f(\ep)}_X^a}^{\rc a}\in [0,\iy).
\]
For $b=a$, 
\[
\ve{f}_a\lesssim \pa{\sumo jn \ve{\pl_j f}_{L_a(\{\pm 1\}^n,X)}^q}^{\rc a}.
\]
%For enflo type
Let $f:\{\pm 1\}^n\to X$ be 
\begin{align*}
\ve{f(\ep)-f(-\ep)}_a
&\le \ve{f(\ep)-\E f}_a + \E\ve{\E f - \E f(-\ep)}_a\\%both are functions with mean 0.$ 
&\lesssim \pa{\sumo jn \ve{f(\ep) - f(\ep_1,\ldots, -\ep_j,\ldots, \ep_n)}_X^a}^{\rc a}.
\end{align*}

We need some facts about the heat semigroup.
\begin{fct}[Fact 1]
Heat flow is a contraction:
\[
\ve{e^{-t\De}f}_{L_q(\{\pm 1\}^n,X)}\le \ve{f}_{L_q(\{\pm 1\}^n,X)}.
\]
\end{fct}
\begin{proof}
We have
\[
e^{-t\De} f = \sum_{A\subeq \{1,\ldots, n\}}e^{-t|A|}\wh f(A) W_A = \sum R_t*f
%
\]
Here the convolution is defined as $\rc{2^n}\sum_{\de\in \{\pm 1\}^n} R_t(\ep\de)f(\de)$. %multiplicative boolean
This is a vector valued function. In the real case it's Parseval, multiplying the Fourier coefficients. 
%as long as not norms, identities of vectors. 
It's enough to prove for the real line. Identities on the level of vectors. 
Here
\[
R_t(\ep)=\sum_{A\subeq \{1,\ldots, n\}}  e^{-t|A|}W_A(\ep);
%no parseval ofr norms
\]
this is the Riesz product.

The function is 
\[
= \prod_{i=1}^n (1+e^{-t}\ep_i)=0,t>0.
\]
$\E R_t=1$ so $R_t$ is a probability measure and heat flow is an averaging operator.
%lots of Fourier analysis in next class.
\end{proof}